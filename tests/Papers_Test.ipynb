{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating tests for a varied set of documents, models and dimensions on the papers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ai_set = pd.read_csv('../examples/datasets/ai_papers.csv')\n",
    "dl_set = pd.read_csv('../examples//datasets/dl_papers.csv')\n",
    "cv_set = pd.read_csv('../examples//datasets/cv_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Pipeline para acelerar transformação para Dataset do HuggingFace\n",
    "\n",
    "def hf_pipeline(data):\n",
    "    from datasets import Dataset, ClassLabel\n",
    "\n",
    "    unique_classes = data['label'].unique()\n",
    "\n",
    "    dataframe = Dataset.from_pandas(data)\n",
    "    class_label = ClassLabel(names=list(unique_classes))\n",
    "\n",
    "    dataframe = dataframe.cast_column('label', class_label)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def treat_datasets(n_papers=50):\n",
    "    # Create new DataFrames with labels directly\n",
    "    ai_papers = ai_set.iloc[:n_papers, :].assign(label=\"Artificial Intelligence\")\n",
    "    dl_papers = dl_set.iloc[:n_papers, :].assign(label=\"Digital Libraries\")\n",
    "    cv_papers = cv_set.iloc[:n_papers, :].assign(label=\"Computer Vision\")\n",
    "\n",
    "    # Concatenate\n",
    "    papers = pd.concat([ai_papers, dl_papers, cv_papers], ignore_index=True)\n",
    "    \n",
    "    # Clean up columns\n",
    "    papers = papers.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "    \n",
    "    # Select and rename columns\n",
    "    abstracts = papers[['abstract', 'label']].rename(columns={'abstract': 'text'})\n",
    "    \n",
    "    return hf_pipeline(abstracts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lipecorradini/.cache/pypoetry/virtualenvs/llm-mri-RE74i_Ji-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Model -  distilbert-base-uncased with  20  papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 60/60 [00:00<00:00, 13240.29 examples/s]\n",
      "Map: 100%|██████████| 60/60 [00:00<00:00, 2110.15 examples/s]\n",
      "Map: 100%|██████████| 60/60 [00:21<00:00,  2.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 22.14 seconds\n",
      "torch.Size([60])\n",
      "torch.Size([60])\n",
      "Evaluating model with 5 components: 0.099 score!\n",
      "torch.Size([60])\n",
      "torch.Size([60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62344/287146944.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_score = pd.concat([df_score, pd.DataFrame([new_evaluation])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with 10 components: 0.022 score!\n",
      "torch.Size([60])\n",
      "torch.Size([60])\n",
      "Evaluating model with 20 components: 0.020 score!\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Model -  distilbert-base-uncased with  50  papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 150/150 [00:00<00:00, 44594.95 examples/s]\n",
      "Map: 100%|██████████| 150/150 [00:00<00:00, 2568.50 examples/s]\n",
      "Map: 100%|██████████| 150/150 [01:04<00:00,  2.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 64.80 seconds\n",
      "torch.Size([150])\n",
      "torch.Size([150])\n",
      "Evaluating model with 12 components: -0.020 score!\n",
      "torch.Size([150])\n",
      "torch.Size([150])\n",
      "Evaluating model with 25 components: -0.003 score!\n",
      "torch.Size([150])\n",
      "torch.Size([150])\n",
      "Evaluating model with 50 components: -0.020 score!\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Model -  distilbert-base-uncased with  100  papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 300/300 [00:00<00:00, 65937.81 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 1782.55 examples/s]\n",
      "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
     ]
    }
   ],
   "source": [
    "from llm_mri import ActivationAreas, Evaluation\n",
    "from llm_mri.dimensionality_reduction import PCA\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# Suppress the SettingWithCopyWarning\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "n_papers = [20, 50, 100]\n",
    "models = {'distilbert-base-uncased':'67M', 'bert-base-uncased':'110M', 'google-bert/bert-large-uncased':'330M'}\n",
    "df_score = pd.DataFrame(columns=['model', 'documents', 'model_size', 'components', 'score', 'processing_time', 'hidden_states_size'])\n",
    "\n",
    "for model in models:\n",
    "    for paper in n_papers:\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"Model - \", model, \"with \", paper, \" papers\")\n",
    "        abstracts = treat_datasets(n_papers=paper)\n",
    "        pca = PCA(n_components=paper)\n",
    "        \n",
    "        llm_mri = ActivationAreas(model=model, device=\"cpu\", dataset=abstracts, reduction_method=pca)\n",
    "        \n",
    "        # Time the processing\n",
    "        start_time = time.time()\n",
    "        llm_mri.process_activation_areas()\n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"Total time: {processing_time:.2f} seconds\")\n",
    "\n",
    "        # Get hidden states dataset size in bytes\n",
    "        hidden_states_size = sys.getsizeof(llm_mri.hidden_states_dataset)\n",
    "\n",
    "        for components in [int(paper / 4), int(paper / 2), paper]:\n",
    "            evaluation = Evaluation(llm_mri, n_components=components)\n",
    "            results = evaluation.evaluate_model()\n",
    "            # Append results to DataFrame\n",
    "            new_evaluation = {\n",
    "                'model': model,\n",
    "                'documents': paper * 3,  # 3 datasets combined\n",
    "                'model_size': models[model],\n",
    "                'components': components,\n",
    "                'score': results['f1_score_difference'],\n",
    "                'processing_time': processing_time , # Add processing time,\n",
    "                'hidden_states_size': hidden_states_size  # Add hidden states size\n",
    "            }\n",
    "            print(f\"Evaluating model with {components} components: {results['f1_score_difference']:.3f} score!\")\n",
    "            \n",
    "            df_score = pd.concat([df_score, pd.DataFrame([new_evaluation])], ignore_index=True)\n",
    "        print(\"\\n\")\n",
    "# Display the final DataFrame\n",
    "print(df_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-mri-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
